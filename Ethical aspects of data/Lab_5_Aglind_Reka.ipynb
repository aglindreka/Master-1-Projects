{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2e3d9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"font-size:3rem;color:#325B74;\">Lab 5</h1>\n",
    "\n",
    "## Ethical aspects of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fee68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a972f946",
   "metadata": {},
   "source": [
    "<h2> The COMPAS dataset. What happens if we change the choice of variables? Can we make our decision more fair?</h2> \n",
    "\n",
    "Let's take our own decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a6d3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "# filter dplyr warnings\n",
    "%load_ext rpy2.ipython\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9768d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"id\"                      \"name\"                   \n",
      " [3] \"first\"                   \"last\"                   \n",
      " [5] \"compas_screening_date\"   \"sex\"                    \n",
      " [7] \"dob\"                     \"age\"                    \n",
      " [9] \"age_cat\"                 \"race\"                   \n",
      "[11] \"juv_fel_count\"           \"decile_score\"           \n",
      "[13] \"juv_misd_count\"          \"juv_other_count\"        \n",
      "[15] \"priors_count\"            \"days_b_screening_arrest\"\n",
      "[17] \"c_jail_in\"               \"c_jail_out\"             \n",
      "[19] \"c_case_number\"           \"c_offense_date\"         \n",
      "[21] \"c_arrest_date\"           \"c_days_from_compas\"     \n",
      "[23] \"c_charge_degree\"         \"c_charge_desc\"          \n",
      "[25] \"is_recid\"                \"r_case_number\"          \n",
      "[27] \"r_charge_degree\"         \"r_days_from_arrest\"     \n",
      "[29] \"r_offense_date\"          \"r_charge_desc\"          \n",
      "[31] \"r_jail_in\"               \"r_jail_out\"             \n",
      "[33] \"violent_recid\"           \"is_violent_recid\"       \n",
      "[35] \"vr_case_number\"          \"vr_charge_degree\"       \n",
      "[37] \"vr_offense_date\"         \"vr_charge_desc\"         \n",
      "[39] \"type_of_assessment\"      \"decile_score.1\"         \n",
      "[41] \"score_text\"              \"screening_date\"         \n",
      "[43] \"v_type_of_assessment\"    \"v_decile_score\"         \n",
      "[45] \"v_score_text\"            \"v_screening_date\"       \n",
      "[47] \"in_custody\"              \"out_custody\"            \n",
      "[49] \"priors_count.1\"          \"start\"                  \n",
      "[51] \"end\"                     \"event\"                  \n",
      "[53] \"two_year_recid\"         \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(dplyr)\n",
    "#You can choose your favorite option:\n",
    "#a)Download the dataset and access it locally\n",
    "raw_data <- read.csv(\"./compas-scores-two-years.csv\") \n",
    "#b)Access the dataset directly from the repository\n",
    "#raw_data <- read.csv(\"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\")\n",
    "nrow(raw_data)\n",
    "colnames(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd678ec",
   "metadata": {},
   "source": [
    "Note: if you obtain the following error: \"UsageError: Cell magic `%%R` not found.\"\n",
    "Try this solution: pip install rpy2\n",
    "\n",
    "\n",
    "## Filtering of data\n",
    "\n",
    "<em>In a 2009 study examining the predictive power of its COMPAS score, Northpointe defined recidivism as “a finger-printable arrest involving a charge and a filing for any uniform crime reporting (UCR) code.” We interpreted that to mean a criminal offense that resulted in a jail booking and took place after the crime for which the person was COMPAS scored.\n",
    "\n",
    "It was not always clear, however, which criminal case was associated with an individual’s COMPAS score. To match COMPAS scores with accompanying cases, we considered cases with arrest dates or charge dates within 30 days of a COMPAS assessment being conducted. In some instances, we could not find any corresponding charges to COMPAS scores. We removed those cases from our analysis.\n",
    "\n",
    "Next, we sought to determine if a person had been charged with a new crime subsequent to crime for which they were COMPAS screened. We did not count traffic tickets and some municipal ordinance violations as recidivism. We did not count as recidivists people who were arrested for failing to appear at their court hearings, or people who were later charged with a crime that occurred prior to their COMPAS screening.</em>\n",
    "\n",
    "We do the same filtering that in the Propublica Study **BUT** we select different variables.\n",
    "\n",
    "Finally we save the filtered csv file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c09b7fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6172\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "df <- dplyr::select(raw_data, age, c_charge_degree, race, age_cat, score_text, sex, priors_count, \n",
    "                    days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out,\n",
    "                    juv_fel_count,juv_misd_count,juv_other_count,is_violent_recid) %>% \n",
    "        filter(days_b_screening_arrest <= 30) %>%\n",
    "        filter(days_b_screening_arrest >= -30) %>%\n",
    "        filter(is_recid != -1) %>%\n",
    "        filter(is_violent_recid != -1) %>%\n",
    "        filter(c_charge_degree != \"O\") %>%\n",
    "        filter(score_text != 'N/A')\n",
    "write.csv(df,\"propublica_ext.csv\")\n",
    "\n",
    "nrow(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36deb31a",
   "metadata": {},
   "source": [
    "Now we import the same libraries as in the previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f81e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # for generating synthetic data \n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdce0d7",
   "metadata": {},
   "source": [
    "We first read the filtered data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b16f6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: 6172\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"propublica_ext.csv\")\n",
    "\n",
    "print(\"Size of the dataset: %d\" % len(df.index)) #We calculate the number of objects in the dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2b9cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 6170 6171 6172]\n",
      "[69 34 24 44 41 43 39 27 23 37 47 31 25 64 21 32 26 33 30 55 49 29 51 35\n",
      " 28 53 38 22 62 56 45 40 50 20 36 54 19 42 52 59 61 63 48 46 58 78 57 66\n",
      " 70 60 65 68 71 83 67 75 72 74 96 73 80 77 76 79 18]\n",
      "['F' 'M']\n",
      "['Other' 'African-American' 'Caucasian' 'Hispanic' 'Asian'\n",
      " 'Native American']\n",
      "['Greater than 45' '25 - 45' 'Less than 25']\n",
      "['Low' 'Medium' 'High']\n",
      "['Male' 'Female']\n",
      "[ 0  4 14  3  1  7  6  5 13  8  9 21  2 15 10 28 19 11 23 25 36 12 20 33\n",
      " 16 18 17 22 30 24 27 26 37 29 31 38]\n",
      "[ -1   0 -20  22  -2 -24 -13 -15 -10 -30  -4 -16 -26  -7  29  -3  23 -11\n",
      " -22 -21 -12  -8  -5 -23 -14  -9  -6 -27 -19 -18  26 -29  28   7 -17 -28\n",
      "   9 -25  13  20  17  30   6   2  16   8   1  18  15  21  27  11   3  14\n",
      "   5  24]\n",
      "[ 1  3  4  6 10  5  9  2  7  8]\n",
      "[0 1]\n",
      "[0 1]\n",
      "['2013-08-13 06:03:42' '2013-01-26 03:45:27' '2013-04-13 04:58:34' ...\n",
      " '2014-01-13 05:48:01' '2014-03-08 08:06:02' '2014-06-28 12:16:41']\n",
      "['2013-08-14 05:41:20' '2013-02-05 05:36:53' '2013-04-14 07:02:04' ...\n",
      " '2014-01-14 07:49:46' '2014-03-09 12:18:04' '2014-06-30 11:19:23']\n",
      "[ 0  2  1  8  3  4 20  6  5 10]\n",
      "[ 0  1  6 12  2  4  3  8  5 13]\n",
      "[0 1 3 4 2 9 5 6 7]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b0107",
   "metadata": {},
   "source": [
    "We need to binarize all the categorical features we considered in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78967310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 6172 objects and 25 variables\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>...</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>other</th>\n",
       "      <th>less_than_25</th>\n",
       "      <th>between_25_45</th>\n",
       "      <th>greater_than_25</th>\n",
       "      <th>score_low</th>\n",
       "      <th>score_medium</th>\n",
       "      <th>score_high</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  priors_count  days_b_screening_arrest  decile_score  \\\n",
       "0           1   69             0                       -1             1   \n",
       "1           2   34             0                       -1             3   \n",
       "2           3   24             4                       -1             4   \n",
       "3           4   44             0                        0             1   \n",
       "4           5   41            14                       -1             6   \n",
       "\n",
       "   is_recid  two_year_recid  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "0         0               0              0               0                0   \n",
       "1         1               1              0               0                0   \n",
       "2         1               1              0               0                1   \n",
       "3         0               0              0               0                0   \n",
       "4         1               1              0               0                0   \n",
       "\n",
       "   ...  hispanic  asian  other  less_than_25  between_25_45  greater_than_25  \\\n",
       "0  ...         0      0      1             0              0                1   \n",
       "1  ...         0      0      0             0              1                0   \n",
       "2  ...         0      0      0             1              0                0   \n",
       "3  ...         0      0      1             0              1                0   \n",
       "4  ...         0      0      0             0              1                0   \n",
       "\n",
       "   score_low  score_medium  score_high  Male  \n",
       "0          1             0           0     1  \n",
       "1          1             0           0     1  \n",
       "2          1             0           0     1  \n",
       "3          1             0           0     1  \n",
       "4          0             1           0     1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pd.read_csv(\"propublica_ext.csv\")\n",
    "    #We first binarize the categorical feature c_charge_degree\n",
    "    .assign(c_charge=lambda x:x['c_charge_degree'].replace({'F': 1, 'M':0}))\n",
    "    #race\n",
    "    .assign(african_american=lambda x:x['race'].replace({'Other': 0, 'African-American': 1, 'Caucasian': 0, 'Hispanic': 0, 'Asian': 0,'Native American': 0}))\n",
    "    .assign(caucasian=lambda x:x['race'].replace({'Other': 0, 'African-American': 0, 'Caucasian': 1, 'Hispanic': 0, 'Asian': 0,'Native American': 0}))\n",
    "    .assign(native_american=lambda x:x['race'].replace({'Other': 0, 'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Asian': 0,'Native American': 1}))\n",
    "    .assign(hispanic=lambda x:x['race'].replace({'Other': 0, 'African-American': 0, 'Caucasian': 0, 'Hispanic': 1, 'Asian': 0,'Native American': 0}))\n",
    "    .assign(asian=lambda x:x['race'].replace({'Other': 0, 'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Asian': 1,'Native American': 0}))\n",
    "    .assign(other=lambda x:x['race'].replace({'Other': 1, 'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Asian': 0,'Native American': 0}))\n",
    "    #age_cat\n",
    "    .assign(less_than_25=lambda x:x['age_cat'].replace({'Greater than 45':0, '25 - 45':0, 'Less than 25':1}))\n",
    "    .assign(between_25_45=lambda x:x['age_cat'].replace({'Greater than 45':0, '25 - 45':1, 'Less than 25':0}))\n",
    "    .assign(greater_than_25=lambda x:x['age_cat'].replace({'Greater than 45':1, '25 - 45':0, 'Less than 25':0}))\n",
    "    #score_text\n",
    "    .assign(score_low=lambda x:x['score_text'].replace({'Low':1, 'Medium':0, 'High':0}))\n",
    "    .assign(score_medium=lambda x:x['score_text'].replace({'Low':0, 'Medium':1, 'High':0}))\n",
    "    .assign(score_high=lambda x:x['score_text'].replace({'Low':0, 'Medium':0, 'High':1}))\n",
    "    #sex\n",
    "    .assign(Male=lambda x:x['sex'].replace({'Male': 1, 'Female':0}))\n",
    "    \n",
    ")\n",
    "DeleteList=['c_charge_degree','race','age_cat','score_text','sex','c_jail_in','c_jail_out']\n",
    "df=df.drop(DeleteList, axis=1)\n",
    "print(\"Dataset with %d\" % df.shape[0],\"objects and %d\" % df.shape[1], \"variables\") #We calculate the number of objects in the dataset\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020e6e",
   "metadata": {},
   "source": [
    "Actually, our dataset is only composed of 23 variables, since we do not include the first column as variable, and the variable \"two_year_recid\" is the binary label to predict.\n",
    "\n",
    "We then define our data and our label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "94538ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'priors_count', 'days_b_screening_arrest',\n",
       "       'decile_score', 'is_recid', 'two_year_recid', 'juv_fel_count',\n",
       "       'juv_misd_count', 'juv_other_count', 'is_violent_recid', 'c_charge',\n",
       "       'african_american', 'caucasian', 'native_american', 'hispanic', 'asian',\n",
       "       'other', 'less_than_25', 'between_25_45', 'greater_than_25',\n",
       "       'score_low', 'score_medium', 'score_high', 'Male'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ddcfb",
   "metadata": {},
   "source": [
    "We now select from this list only the variables we want to consider in our classification problem and the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f98c91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a way to select these columns using the column names\n",
    "    \n",
    "#feature_columns = ['Number_of_Priors', 'score_factor','Age_Above_FourtyFive', 'Age_Below_TwentyFive', 'African_American','Asian', 'Hispanic', 'Native_American', 'Other', 'Female',       'Misdemeanor']\n",
    "\n",
    "feature_columns = ['age', 'priors_count', 'days_b_screening_arrest',\n",
    "         'juv_fel_count',\n",
    "       'juv_misd_count', 'juv_other_count', 'is_violent_recid', 'c_charge',\n",
    "        'less_than_25', 'between_25_45', 'greater_than_25',\n",
    "        'Male']\n",
    "\n",
    "\n",
    "data = df[feature_columns].values\n",
    "y = df['two_year_recid'].values\n",
    "df=df.assign(COMPAS_Decision=lambda x:x['score_low'].replace({0: 1, 1:0}))\n",
    "y_compas = df['COMPAS_Decision'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78125675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the libraries for the SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle the data\n",
    "#n_samples=data.shape[0]\n",
    "#perm = list(range(0,n_samples))\n",
    "#shuffle(perm)\n",
    "#data = data[perm]\n",
    "#y = y[perm]\n",
    "#y_compas=y_compas[perm]\n",
    "\n",
    "\n",
    "#Create train and validation set\n",
    "#train_x, test_x, train_y, test_y = train_test_split(data, y, test_size=0.1, shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=1.0)\n",
    "svm_clf.fit(data, y)\n",
    "\n",
    "y_pred=svm_clf.predict(data)\n",
    "\n",
    "\n",
    "#svm_clf = SVC(kernel=\"linear\", C=1.0)\n",
    "#svm_clf.fit(train_x, train_y)\n",
    "\n",
    "#ytrain_pred=svm_clf.predict(train_x)\n",
    "#ytest_pred=svm_clf.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63c77324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy SVM (All):  \t 70.01 %\n",
      " Accuracy SVM (Black):\t 68.57 %\n",
      " Accuracy SVM (White):\t 71.18 %\n",
      "\n",
      "FPR SVM 9.60 %\n",
      "FNR SVM 54.40 %\n"
     ]
    }
   ],
   "source": [
    "b_recid = df[df['african_american'] == 1]\n",
    "w_recid = df[df['caucasian'] == 1]\n",
    "print(\n",
    "    ' Accuracy SVM (All):  \\t %.2f' % (metrics.accuracy_score(y, y_pred)*100), \"%\\n\",\n",
    "    'Accuracy SVM (Black):\\t %.2f' % (metrics.accuracy_score(y_pred[df['african_american'] == 1], b_recid['two_year_recid'])*100),\"%\\n\", \n",
    "    'Accuracy SVM (White):\\t %.2f' % (metrics.accuracy_score(y_pred[df['caucasian'] == 1], w_recid['two_year_recid'])*100),\"%\\n\",\n",
    "\n",
    ")\n",
    "\n",
    "pd.crosstab(y_pred, df['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')\n",
    "\n",
    "FPR_s=pd.crosstab(y_pred, df['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "FNR_s=pd.crosstab(y_pred, df['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "\n",
    "print(\"FPR SVM %.2f\" % (FPR_s*100),\"%\")\n",
    "print(\"FNR SVM %.2f\" % (FNR_s*100),\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368a119",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "**1-** Provide the accuracy for the COMPAS algorithm.\n",
    "\n",
    "**2-** Provide the accuracy for black defendants for the COMPAS algorithm.\n",
    "\n",
    "**3-** Provide the accuracy for white defendants for the COMPAS algorithm.\n",
    "\n",
    "**4-** Provide the FPR for the COMPAS algorithm.\n",
    "\n",
    "**5-** Provide the FNR for the COMPAS algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8c5f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.1 %\n"
     ]
    }
   ],
   "source": [
    "#1- Provide the accuracy for the COMPAS algorithm.\n",
    "#Accuracy\n",
    "\n",
    "\n",
    "print(\"Accuracy: %.1f\" % (metrics.accuracy_score(y, y_compas)*100), \"%\") #you need to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "031e2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.9 %\n"
     ]
    }
   ],
   "source": [
    "#64.91\n",
    "print(\"Accuracy: %.1f\" % (metrics.accuracy_score(y[df['african_american'] == 1], y_compas[df['african_american'] == 1])*100), \"%\") #you need to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2a8b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.2 %\n"
     ]
    }
   ],
   "source": [
    "#67.19\n",
    "#3- Provide the accuracy for white defendants for the COMPAS algorithm.\n",
    "print(\"Accuracy: %.1f\" % (metrics.accuracy_score(y[df['caucasian'] == 1], y_compas[df['caucasian'] == 1])*100), \"%\") #you need to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1afbe453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR Compass 30.27 %\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#30.27\n",
    "#Provide the FPR for the COMPAS algorithm.\n",
    "FPR_s=pd.crosstab(y_compas, df['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "print(\"FPR Compass %.2f\" % (FPR_s*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9daf78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNR Compass 38.31 %\n"
     ]
    }
   ],
   "source": [
    "#5- Provide the FNR for the COMPAS algorithm.\n",
    "#38.31\n",
    "FNR_s=pd.crosstab(y_compas, df['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "print(\"FNR Compass %.2f\" % (FNR_s*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "419a97b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR of Black 42.34 %\n",
      "FNR of Black 28.48 %\n"
     ]
    }
   ],
   "source": [
    "#We calculate FPR and FNR for black defendants for the COMPAS algorithm:\n",
    "FPR_b=pd.crosstab(b_recid['COMPAS_Decision'], b_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "FNR_b=pd.crosstab(b_recid['COMPAS_Decision'], b_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "\n",
    "print(\"FPR of Black %.2f\" % (FPR_b*100),\"%\")\n",
    "print(\"FNR of Black %.2f\" % (FNR_b*100),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2541907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR of White 22.01 %\n",
      "FNR of White 49.64 %\n"
     ]
    }
   ],
   "source": [
    "#exercise 6 and 7\n",
    "FPR_b=pd.crosstab(w_recid['COMPAS_Decision'], w_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "FNR_b=pd.crosstab(w_recid['COMPAS_Decision'], w_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "\n",
    "print(\"FPR of White %.2f\" % (FPR_b*100),\"%\")\n",
    "print(\"FNR of White %.2f\" % (FNR_b*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0eaaeec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9236710586097228\n",
      "1.7429775280898876\n"
     ]
    }
   ],
   "source": [
    "#Exercise 8 and 9\n",
    "\n",
    "#\"FPR of Black is 1.9 times greater than for White\"\n",
    "print(42.34/22.01)\n",
    "#\"FNR of Black is 1.7 times smaller than for White\"\n",
    "print(49.64/28.48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc053aa",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "For the COMPAS algorithm:\n",
    "\n",
    "**6-** Calculate the FPR for white defendants.\n",
    "\n",
    "**7-** Calculate the FNR for white defendants.\n",
    "\n",
    "**8-** Replace **x** by the right number in the two following statement:\n",
    "\n",
    "\"FPR of Black is **x** times greater than for White\"\n",
    "\n",
    "**9-** Replace **x** by the right number in the two following statement:\n",
    "\n",
    "\"FNR of Black is **x** times smaller than for White\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a6315040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR of Black 13.74 %\n",
      "FNR of Black 47.56 %\n"
     ]
    }
   ],
   "source": [
    "#For the SVM:\n",
    "FPR_b=pd.crosstab(y_pred[df['african_american'] == 1], b_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "FNR_b=pd.crosstab(y_pred[df['african_american'] == 1], b_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "\n",
    "print(\"FPR of Black %.2f\" % (FPR_b*100),\"%\")\n",
    "print(\"FNR of Black %.2f\" % (FNR_b*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "93656263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR of White 6.48 %\n",
      "FNR of White 63.63 %\n"
     ]
    }
   ],
   "source": [
    "#10- Calculate the FPR for white defendants.\n",
    "#11- Calculate the FNR for white defendants.\n",
    "#For the SVM:\n",
    "FPR_b=pd.crosstab(y_pred[df['caucasian'] == 1], w_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[0][1]\n",
    "FNR_b=pd.crosstab(y_pred[df['caucasian'] == 1], w_recid['two_year_recid'], rownames=['Predicted recividism'],colnames=['Actual recividism'],normalize='columns')[1][0].astype('float')\n",
    "\n",
    "print(\"FPR of White %.2f\" % (FPR_b*100),\"%\")\n",
    "print(\"FNR of White %.2f\" % (FNR_b*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd96c6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1203703703703702"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12- Replace x by the right number in the two following statement:\n",
    "\n",
    "#\"FPR of Black is x times greater than for White\"\n",
    "13.74/6.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "26aa088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7474461731887474"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13- Replace x by the right number in the two following statement:\n",
    "\n",
    "#\"FNR of Black is x times smaller than for White\"\n",
    "47.56/63.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e9b1f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15- Which is the best solution in terms of accuracy? Is it fair (in terms of accuracy)?\n",
    "#the SVM is biger and so it's better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9fc2d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16- Which is the best solution in terms of FPR? Based on answers 8 and 12,\n",
    "#which solution is more fair (in terms of FPR)?\n",
    "#for FPR,SVM is smaller, so it's more fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17- Which is the best solution in terms of FNR? Based on answers 9 and 13, \n",
    "#which solution is more fair (in terms of FNR)?\n",
    "#FNR in Compass is smaller, so it's more fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0928fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_opportunity(y,y_pred, x_prot):\n",
    "    Pos_pro=0.0\n",
    "    Pos_nonpro=0.0\n",
    "    PPos_pro=0.0\n",
    "    PPos_nonpro=0.0\n",
    "    \n",
    "    n=y_pred.size\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if (y[i]==1 and x_prot[i]==0):\n",
    "            Pos_nonpro=Pos_nonpro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_nonpro=PPos_nonpro+1\n",
    "        if (y[i]==1 and x_prot[i]==1):\n",
    "            Pos_pro=Pos_pro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_pro=PPos_pro+1\n",
    "    #print(Pos_nonpro)\n",
    "    #print(Pos_pro)\n",
    "    #print(PPos_pro)\n",
    "    #print(PPos_nonpro)\n",
    "    UNF_EOpp=abs((PPos_nonpro/Pos_nonpro)-(PPos_pro/Pos_pro))\n",
    "    \n",
    "    return UNF_EOpp\n",
    "\n",
    "def predictiv_equality(y,y_pred, x_prot):\n",
    "    Pos_pro=0.0\n",
    "    Pos_nonpro=0.0\n",
    "    PPos_pro=0.0\n",
    "    PPos_nonpro=0.0\n",
    "    \n",
    "    n=y_pred.size\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if (y[i]==0 and x_prot[i]==0):\n",
    "            Pos_nonpro=Pos_nonpro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_nonpro=PPos_nonpro+1\n",
    "        if (y[i]==0 and x_prot[i]==1):\n",
    "            Pos_pro=Pos_pro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_pro=PPos_pro+1\n",
    "    #print(Pos_nonpro)\n",
    "    #print(Pos_pro)\n",
    "    #print(PPos_pro)\n",
    "    #print(PPos_nonpro)\n",
    "    UNF_PE =abs((PPos_nonpro/Pos_nonpro)-(PPos_pro/Pos_pro))\n",
    "    \n",
    "    return UNF_PE\n",
    "\n",
    "def equalized_odds(y,y_pred, x_prot):\n",
    "    return equal_opportunity(y,y_pred, x_prot) + predictive_equality(y,y_pred, x_prot)\n",
    "\n",
    "def predictiv_parity(y,y_pred, x_prot):\n",
    "    Pos_pro=0.0\n",
    "    Pos_nonpro=0.0\n",
    "    PPos_pro=0.0\n",
    "    PPos_nonpro=0.0\n",
    "    \n",
    "    n=y_pred.size\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if (y_pred[i]==1 and x_prot[i]==0):\n",
    "            Pos_nonpro=Pos_nonpro+1\n",
    "            if (y[i]==1):\n",
    "                PPos_nonpro=PPos_nonpro+1\n",
    "        if (y_pred[i]==1 and x_prot[i]==1):\n",
    "            Pos_pro=Pos_pro+1\n",
    "            if (y[i]==1):\n",
    "                PPos_pro=PPos_pro+1\n",
    "    #print(Pos_nonpro)\n",
    "    #print(Pos_pro)\n",
    "    #print(PPos_pro)\n",
    "    #print(PPos_nonpro)\n",
    "    UNF_PE =abs((PPos_nonpro/Pos_nonpro)-(PPos_pro/Pos_pro))\n",
    "    \n",
    "    return UNF_PE\n",
    "def statistical_parity(y,y_pred, x_prot):\n",
    "    Pos_pro=0.0\n",
    "    Pos_nonpro=0.0\n",
    "    PPos_pro=0.0\n",
    "    PPos_nonpro=0.0\n",
    "    \n",
    "    n=y_pred.size\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if (x_prot[i]==0):\n",
    "            Pos_nonpro=Pos_nonpro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_nonpro=PPos_nonpro+1\n",
    "        if (x_prot[i]==1):\n",
    "            Pos_pro=Pos_pro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_pro=PPos_pro+1\n",
    "    #print(Pos_nonpro)\n",
    "    #print(Pos_pro)\n",
    "    #print(PPos_pro)\n",
    "    #print(PPos_nonpro)\n",
    "    UNF_SP=abs((PPos_nonpro/Pos_nonpro)-(PPos_pro/Pos_pro))\n",
    "    \n",
    "    return UNF_SP\n",
    "\n",
    "def disparate_impact(y,y_pred, x_prot):\n",
    "    Pos_pro=0.0\n",
    "    Pos_nonpro=0.0\n",
    "    PPos_pro=0.0\n",
    "    PPos_nonpro=0.0\n",
    "    \n",
    "    n=y_pred.size\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if (x_prot[i]==0):\n",
    "            Pos_nonpro=Pos_nonpro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_nonpro=PPos_nonpro+1\n",
    "        if (x_prot[i]==1):\n",
    "            Pos_pro=Pos_pro+1\n",
    "            if (y_pred[i]==1):\n",
    "                PPos_pro=PPos_pro+1\n",
    "    #print(Pos_nonpro)\n",
    "    #print(Pos_pro)\n",
    "    #print(PPos_pro)\n",
    "    #print(PPos_nonpro)\n",
    "    UNF_DI=min((PPos_pro/Pos_pro)/(PPos_nonpro/Pos_nonpro), (PPos_nonpro/Pos_nonpro)/(PPos_pro/Pos_pro))\n",
    "    \n",
    "    return UNF_DI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "66d1ce5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EO</td>\n",
       "      <td>0.240493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PE</td>\n",
       "      <td>0.219488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EOD</td>\n",
       "      <td>0.459981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP</td>\n",
       "      <td>0.058429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.268422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DI</td>\n",
       "      <td>0.534041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metrics    values\n",
       "0      EO  0.240493\n",
       "1      PE  0.219488\n",
       "2     EOD  0.459981\n",
       "3      PP  0.058429\n",
       "4      SP  0.268422\n",
       "5      DI  0.534041"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18- Calculate the 6 fairness metrics for the COMPAS classifier.\n",
    "UNF_EOpp=equal_opportunity(y,y_compas,df['african_american'])\n",
    "UNF_PE=predictiv_equality(y,y_compas,df['african_american'])\n",
    "UNF_EOd=equalized_odds(y,y_compas,df['african_american'])\n",
    "UNF_PP=predictiv_parity(y,y_compas,df['african_american'])\n",
    "UNF_SP=statistical_parity(y,y_compas,df['african_american'])\n",
    "UNF_DI=disparate_impact(y,y_compas,df['african_american'])\n",
    "liste=[UNF_EOpp,UNF_PE,UNF_EOd,UNF_PP,UNF_SP,UNF_DI]\n",
    "mat = [\"EO\", \"PE\", \"EOD\", \"PP\", \"SP\", \"DI\"]\n",
    "\n",
    "pd.DataFrame({\"metrics\": mat, \"values\": liste})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "008a4a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EO</td>\n",
       "      <td>0.167240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PE</td>\n",
       "      <td>0.075189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EOD</td>\n",
       "      <td>0.242429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP</td>\n",
       "      <td>0.026277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.164667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DI</td>\n",
       "      <td>0.515460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metrics    values\n",
       "0      EO  0.167240\n",
       "1      PE  0.075189\n",
       "2     EOD  0.242429\n",
       "3      PP  0.026277\n",
       "4      SP  0.164667\n",
       "5      DI  0.515460"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the 6 fairness metrics for the SVM classifier.\n",
    "UNF_EOpp=equal_opportunity(y,y_pred,df['african_american'])\n",
    "UNF_PE=predictiv_equality(y,y_pred,df['african_american'])\n",
    "UNF_EOd=equalized_odds(y,y_pred,df['african_american'])\n",
    "UNF_PP=predictiv_parity(y,y_pred,df['african_american'])\n",
    "UNF_SP=statistical_parity(y,y_pred,df['african_american'])\n",
    "UNF_DI=disparate_impact(y,y_pred,df['african_american'])\n",
    "liste=[UNF_EOpp,UNF_PE,UNF_EOd,UNF_PP,UNF_SP,UNF_DI]\n",
    "mat = [\"EO\", \"PE\", \"EOD\", \"PP\", \"SP\", \"DI\"]\n",
    "\n",
    "pd.DataFrame({\"metrics\": mat, \"values\": liste})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8155a",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "For the SVM classifier:\n",
    "\n",
    "**10-** Calculate the FPR for white defendants.\n",
    "\n",
    "\n",
    "**11-** Calculate the FNR for white defendants.\n",
    "\n",
    "**12-** Replace **x** by the right number in the two following statement:\n",
    "\n",
    "\"FPR of Black is **x** times greater than for White\"\n",
    "\n",
    "**13-** Replace **x** by the right number in the two following statement:\n",
    "\n",
    "\"FNR of Black is **x** times smaller than for White\"\n",
    "\n",
    "**14-** Fill in the following table:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "& \\text{SVM }&\\text{COMPAS }\\\\\n",
    "&\\begin{array}{cccc}\n",
    "\\hline \\hline \n",
    "&\\text { All } & \\text { Black } & \\text { White }\\\\\n",
    "\\hline \n",
    "\\text{Accuracy}& {70.01}&{68.57}  &{71.18}  \\\\\n",
    "\\text{FPR}&{9.60} &{13.74}  & {6.48} \\\\\n",
    "\\text{FNR}&{54.40} &{47.56}  & {63.63} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "&\\begin{array}{cccc}\n",
    "\\hline \\hline \n",
    "&\\text { All } & \\text { Black } & \\text { White }\\\\\n",
    "\\hline \n",
    "\\text{Accuracy}&{66.1} &{64.9}  &{67.2}  \\\\\n",
    "\\text{FPR}&{30.27} &{42.34}  &{22.01}  \\\\\n",
    "\\text{FNR}&{38.31} &{28.48}  &{49.64}  \\\\\n",
    "\\hline\n",
    "\\end{array}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "FPR of White 22.01 %\n",
    "FNR of White 49.64 %\n",
    "\n",
    "**15-** Which is the best solution in terms of accuracy? Is it fair (in terms of accuracy)?\n",
    "\n",
    "**16-** Which is the best solution in terms of FPR? Based on answers 8 and 12, which solution is more fair (in terms of FPR)?\n",
    "\n",
    "**17-** Which is the best solution in terms of FNR? Based on answers 9 and 13, which solution is more fair (in terms of FNR)?\n",
    "\n",
    "**18-** Calculate the 6 fairness metrics for the COMPAS classifier.\n",
    "\n",
    "**19-** Calculate the 6 fairness metrics for the SVM classifier.\n",
    "\n",
    "**20-** As a future (or actual) data scientist, which solution would you choose for **this** specific problem? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll choose SVM, because If I see the accuracy, in SVM is higher accuracy\n",
    "#In FPR is lower, thats mean its better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f884a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
